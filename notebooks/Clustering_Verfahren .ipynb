{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Clustering Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis\n",
    "1. [Daten einlesen](#introduction)\n",
    "    1. [Daten aussuchen](#subparagraph1)\n",
    "    2. [Daten zusammenführen](#subparagraph2)\n",
    "    3. [Daten vorbereiten](#subparagraph3)\n",
    "2. [K-Means](#paragraph1)\n",
    "    1. [PCA davor](#subparagraph2.1)\n",
    "    2. [PCA danach](#subparagraph2.2)\n",
    "3. [Hierarchical Clustering](#paragraph2)\n",
    "    1. [nicht reduziert](#subparagraph3.1)\n",
    "    2. [reduziert](#subparagraph3.2)\n",
    "4. [Gaussian Mixture Model](#paragraph3)\n",
    "5. [Bayes Mixture Model](#paragraph4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# Import necessary libraries\n",
    "from copy import deepcopy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "import sklearn.datasets \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../songs_longtexts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spezielle Daten auswählen <a name=\"subparagraph1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df[df['artist'] == 'Eminem']\n",
    "data2 = df[df['artist'] == 'ABBA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten zusammenführen <a name=\"subparagraph2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten vorbereiten <a name=\"subparagraph3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizor = TfidfVectorizer()\n",
    "tf_idf = tf_idf_vectorizor.fit_transform(data.POS.values.astype(str))\n",
    "tf_idf_norm = normalize(tf_idf)\n",
    "tf_idf_array = tf_idf_norm.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means <a name=\"paragraph2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA davor <a name=\"subparagraph2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "kmeans = KMeans(n_clusters=10, max_iter=600, algorithm = 'auto')\n",
    "fitted = kmeans.fit(Y_sklearn)\n",
    "prediction = kmeans.predict(Y_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], c=prediction, s=70, cmap='viridis')\n",
    "plt.title('PCA')\n",
    "#plt.savefig('K_Means/PCA_K-Means_Lyrics.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA danach <a name=\"subparagraph2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, max_iter=600, algorithm = 'auto')\n",
    "fitted = kmeans.fit(tf_idf_array)\n",
    "prediction = kmeans.predict(tf_idf_array)\n",
    "\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X', 'o', 'v', '^')\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(Y_sklearn[:, 0], Y_sklearn[:, 1],hue=prediction, style=data1.genre1, markers=markers, palette=sns.color_palette(\"hls\", len(np.unique(prediction))))\n",
    "plt.title('PCA')\n",
    "#plt.savefig('K_Means/K-Means_Artists.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HC <a name=\"paragraph2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkage_matrix(n_samples, children, distances):\n",
    "    \"\"\"\n",
    "    create a linkage matrix for the dendogram method in scipy\n",
    "    n_samples: int, number of samples\n",
    "    children: list of lists, clustered data points (should be 2)\n",
    "    distances: list of distances between nodes\n",
    "    \"\"\"\n",
    "    # Create linkage matrix\n",
    "    \n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(children.shape[0])\n",
    "    for i, merge in enumerate(children):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    return np.column_stack([children, distances, counts]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nicht reduziert <a name=\"subparagraph3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(tf_idf_array)\n",
    "link_matrix = linkage_matrix(tf_idf_array.shape[0], model.children_, model.distances_)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('HC')\n",
    "\n",
    "dendrogram(link_matrix, labels = data.artist.values, leaf_font_size=10);\n",
    "#plt.savefig('../images/HC/hc_alternative_rock_dance_pop.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduziert <a name=\"subparagraph3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_cleans = data.sample(frac=0.008)\n",
    "tf_idf_vectorizor = TfidfVectorizer()\n",
    "tf_idf = tf_idf_vectorizor.fit_transform(dfs_cleans.POS.values.astype(str))\n",
    "tf_idf_norm = normalize(tf_idf)\n",
    "tf_idf_array = tf_idf_norm.toarray()\n",
    "\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(tf_idf_array)\n",
    "link_matrix = linkage_matrix(tf_idf_array.shape[0], model.children_, model.distances_)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('HC')\n",
    "\n",
    "dendrogram(link_matrix, labels = data.artist.values, leaf_font_size=10);\n",
    "#plt.savefig('../images/HC/hc_alternative_rock_dance_pop.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model <a name=\"paragraph3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2, n_init=10, covariance_type='full')\n",
    "gmm.fit(tf_idf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gmm.means_)\n",
    "print('\\n')\n",
    "print(gmm.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.linspace(-1, 6), np.linspace(-1,6))\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "Z = gmm.score_samples(XX)\n",
    "Z = Z.reshape((50,50))\n",
    " \n",
    "plt.contour(X, Y, Z)\n",
    "plt.scatter(tf_idf_array[:, 0], tf_idf_array[:, 1])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes GMM <a name=\"paragraph4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/ml-variational-bayesian-inference-for-gaussian-mixture/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training the model \n",
    "vbgm_model_full = BayesianGaussianMixture(n_components = 5, covariance_type ='full') \n",
    "vbgm_model_full.fit(tf_idf_array) \n",
    "  \n",
    "# Storing the labels \n",
    "labels_full = vbgm_model_full.predict(X) \n",
    "print(set(labels_full)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
